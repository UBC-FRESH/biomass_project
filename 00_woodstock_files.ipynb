{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2952d534-038b-4367-9b3f-7603076adc1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook imports raw ws3 input data, reformats and monkey-patches the data, and exports Woodstock formatted input data files (which we will use in other DSS notebooks for this case as the input data files). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8c11e-dbc1-48f1-996c-4109720d5efe",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af9363bb-7465-45e2-a088-ce8c77721049",
   "metadata": {
    "tags": []
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23141f45-1925-43df-8bd4-0dfe8c3fc8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ws3.forest, ws3.core\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "from util import schedule_harvest_areacontrol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd44bc0-6b66-4dd1-9137-8ab51ec3b6b0",
   "metadata": {},
   "source": [
    "Define some key model parameters (will get used but defined here up top for convenience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46e712-2b73-41ee-bdb7-767683a16d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period_length = 10\n",
    "max_age =  1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22316a-e1b1-4aff-8cb7-acdb520e985d",
   "metadata": {},
   "source": [
    "# Import and reformat inventory and yield input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167c8e8-ac87-4e9d-9a18-06d967d7949a",
   "metadata": {},
   "source": [
    "Read forest inventory data into memory (vector polygon GIS data layer with attribute table, in ESRI Shapefile format). This dataset represents a small subset of timber supply area (TSA) 17 in British Columbia. We monkey-patch the inventory data here to make it line up nicely with what we need downstream as input for the ws3 model (i.e., changes we make here to the in-memory dataset are not saved to the original dataset on disk). Most of what we are doing here is setting up the _theme_ columns in the attribute table, which should help newer ws3 users make the connection between input data and the landscape themes in ws3 model further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f617e9-1d23-4e80-9bf1-b77f2dcab25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stands = gpd.read_file('data/tsa17_subset/stands.shp')\n",
    "stands = stands.rename(columns={'thlb':'theme1', 'au':'theme2', 'ldspp':'theme3', 'age2015':'age', 'shape_area':'area' })\n",
    "stands['area'] = stands.geometry.area * 0.0001 # monkey-patch broken area attribute\n",
    "stands.insert(4, 'theme4', stands['theme2'])\n",
    "stands['theme2'] = stands['theme2'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde6cfb-149a-412f-a150-265f2f18c47c",
   "metadata": {},
   "source": [
    "Read yield data from a CSV file and recast AU column data type to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad5570-6e27-439a-917e-c646c1f2bee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yld = pd.read_csv('data/yld.csv')\n",
    "yld['AU'] = yld['AU'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744ac82-6f68-4c3a-8ae6-9ab7816af43c",
   "metadata": {},
   "source": [
    "Create analysis unit (AU) dataframe from stands dataframe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76a9f6-1e84-49c7-b8e2-ad45ae938613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AU = pd.DataFrame(stands['theme2']).drop_duplicates()\n",
    "AU.rename(columns={'theme2':'AU'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f1deb-4de4-41ef-ace3-a49e5c10b5e1",
   "metadata": {},
   "source": [
    "Join `AU` and `yld` dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280c970-ea89-42fd-9d81-cc9507c9edd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yldmerged = pd.merge(AU, yld, on=['AU'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8c9eb4-ad99-44e5-9479-42c2f5464d83",
   "metadata": {},
   "source": [
    "Import CANFI tree species lookup table (associates tree species names with integer numerical values, which we use as theme data values in the ws3 model), and insert species code values into the yield curve dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9e57c-00fa-4864-b2bf-af0b7b361baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "canf = pd.read_csv('data/canfi_species_modified.csv')\n",
    "canf = canf[['name', 'canfi_species']].set_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ec296-4667-42dd-af20-2489ccfde299",
   "metadata": {},
   "source": [
    "Burn CANFI species codes into stand and yield data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bed323-8533-4f06-98f9-c54b2bd53861",
   "metadata": {},
   "outputs": [],
   "source": [
    "stands['theme3'] = stands.apply(lambda row: canf.loc[row['theme3'], 'canfi_species'], axis=1) \n",
    "yldmerged['canfi_species'] = yldmerged.apply(lambda row: canf.loc[row['LDSPP'], 'canfi_species'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27339769-c706-40d4-9713-8719af8e35c5",
   "metadata": {},
   "source": [
    "Add a new `curve_id` colume that has same data values as `AU` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de783f-3fe3-4815-a6fa-b4249aa3da67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yldmerged['curve_id'] = yldmerged['AU'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd383027-0115-4db1-8c79-5fae21f12f10",
   "metadata": {},
   "source": [
    "Save reformatted data to CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f92c80-5dbf-4654-9bd8-69b6b8d4d612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yldmerged.to_csv('data/yldmerged.csv', header=True, index=False)\n",
    "stands.to_csv('data/stands_table.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c94ba-1e79-44f5-ac6c-e3869dfe7972",
   "metadata": {},
   "source": [
    "Rename stuff to match variable names we expect further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe0e7d-f196-4b29-9f5c-98ab933e0a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stands_table = stands\n",
    "curve_points_table = yldmerged\n",
    "curve_points_table.set_index('AU', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1cedd2-6aa2-492d-b3a2-2f9d3f5e591e",
   "metadata": {},
   "source": [
    "# Export Woodstock-formatted input files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683c6c4-9313-437b-ba2f-7e9fc498b91b",
   "metadata": {},
   "source": [
    "We can use the new ws3 model instance we just built to export ws3 input files in Woodstock file format. We do this for three reasons. \n",
    "\n",
    "The first reason is that it will be simpler and more compact in the actual DSS notebook to instantiate the `ForestModel` object from these Woodstock-formatted files (and also this will provide an opportunity to demonstrate the existance and usage of the Woodstock model import functions that are built into ws3). \n",
    "\n",
    "The second reason is that the process of exporting data from a live `ws3.forest.ForestModel` instance to Woodstock-formatted input data files provides some insight into the internal structure and workings of ws3 models (which can be a challenging thing to get started with, particularly if you do not have a lot of experience building and running forest estate models). \n",
    "\n",
    "The third reason is that Woodstock file format is designed to be \"human readable\" (sort of... nobody ever said it would be super easy or super fun). Picking through the exported Woodstock-formatted files might help some people better understand the structure and details of the model we have built. If you have no experience reading Woodstock-formatted model input data files, then this is going to be trickier (unless you pause here and go take an introductory Woodstock training course of sort). Many forest professionals already have familiarity with Woodstock software and its special file format (through having been exposed to this at some point in their career). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c2463-6bd1-4f48-9be6-e9a4621281c7",
   "metadata": {},
   "source": [
    "Start by creating a new subdirectory to hold the new Woodstock-formatted data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c020155-9642-42ed-9519-f0aaa9985648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir data/woodstock_model_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cc5229-5643-44e7-a872-4031a0f535e0",
   "metadata": {},
   "source": [
    "## LANDSCAPE section\n",
    "\n",
    "The LANDSCAPE section defines stratification variables (themes) and stratification variable values (basecodes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30717fff-79f5-4b46-8a3a-ffadea779386",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_cols=['theme0', # TSA \n",
    "            'theme1', # THLB\n",
    "            'theme2', # AU\n",
    "            'theme3', # leading species code\n",
    "            'theme4'  # yield curve ID\n",
    "           ]\n",
    "basecodes = [list(map(lambda x: str(x), stands_table[tc].unique())) for tc in theme_cols]\n",
    "basecodes[2] = list(set(basecodes[2] + list(stands_table['theme2'].astype(str))))\n",
    "basecodes[3] = list(set(basecodes[3] + list(stands_table['theme3'].astype(str))))\n",
    "basecodes[4] = list(set(basecodes[4] + list(stands_table['theme4'].astype(str))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e1957-6ebd-47ab-aa3e-bff2c2ab78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/woodstock_model_files/tsa17.lan', 'w') as file:\n",
    "    print('*THEME Timber Supply Area (TSA)', file=file)\n",
    "    print('tsa17',file=file)\n",
    "    print('*THEME Timber Harvesting Land Base (THLB)', file=file)\n",
    "    for basecode in basecodes[1]: print(basecode, file=file)\n",
    "    print('*THEME Analysis Unit (AU)', file=file)\n",
    "    for basecode in basecodes[2]: print(basecode, file=file)\n",
    "    print('*THEME Leading tree species (CANFI species code)', file=file)\n",
    "    for basecode in basecodes[3]: print(basecode, file=file)\n",
    "    print('*THEME Yield curve ID', file=file)\n",
    "    for basecode in basecodes[4]: print(basecode, file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7bdaf9-e12f-4d7f-9614-fea6953b7a70",
   "metadata": {},
   "source": [
    "## AREAS section\n",
    "\n",
    "The AREAS section defines the initial forest inventory, in terms of how many hectares of which age class are present in which development type (where a development type is defined as a unique sequence of landscape theme variable values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac4c7ca-3404-4eb8-accb-a440dc2490bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gstands = stands_table.groupby(theme_cols+['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3f44f-0a84-43b7-a13d-db7dda4342da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/woodstock_model_files/tsa17.are', 'w') as file:\n",
    "    for name, group in gstands:\n",
    "        dtk, age, area = tuple(map(lambda x: str(x), name[:-1])), int(name[-1]), group['area'].sum()\n",
    "        print('*A', ' '.join(v for v in dtk), age, area, file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc58db-0ed1-45da-8165-4152a4ad2f60",
   "metadata": {},
   "source": [
    "## YIELDS section\n",
    "\n",
    "The YIELDS section defines yield curves (in this example we only track merchantable log volume, but we can use yield curves to track all sorts of other stuff). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5290f0-7a58-40ff-9852-44b444ad6d7e",
   "metadata": {},
   "source": [
    "The following codes insert allomertic parameters to curve points table for biomass calculation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31d99c-107f-4139-9e27-0c48dd921b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff= pd.read_csv('data/allometic_parameters.csv')\n",
    "coeff.set_index('canfi_species', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0665dc-ffa9-4a2b-ab35-a74bf400c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff1= pd.read_csv('data/allometric_coefficient.csv')\n",
    "coeff1.set_index('canfi_species', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48acd4-943a-4dac-a4fc-7429175a46a9",
   "metadata": {},
   "source": [
    "Inserting the allometric parameters mentioned in P.Boudewyn et al. (2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18eb23-1565-4e67-b2f7-cdf2e72ed4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_points_table['a1'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'a1'], axis=1)\n",
    "curve_points_table['a2'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'a2'], axis=1)\n",
    "curve_points_table['a3'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'a3'], axis=1)\n",
    "curve_points_table['b1'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'b1'], axis=1)\n",
    "curve_points_table['b2'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'b2'], axis=1)\n",
    "curve_points_table['b3'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'b3'], axis=1)\n",
    "curve_points_table['c1'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'c1'], axis=1)\n",
    "curve_points_table['c2'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'c2'], axis=1)\n",
    "curve_points_table['c3'] = curve_points_table.apply(lambda row: coeff.loc[row['canfi_species'], 'c3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a759ef1d-98a4-44f0-aa19-d17516ad92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_points_table['a'] = curve_points_table.apply(lambda row: coeff1.loc[row['canfi_species'], 'a'], axis=1)\n",
    "curve_points_table['b'] = curve_points_table.apply(lambda row: coeff1.loc[row['canfi_species'], 'b'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72097cd6-8983-4a24-b3e6-f60fc7b758f6",
   "metadata": {},
   "source": [
    "The following chunk of code extrapolates yield curve for biomass using allometric equations proposed by P.Boudewyn et al. (2007)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fee73b43-f9cf-4eff-9b7e-6e05f7ab45d1",
   "metadata": {},
   "source": [
    "with open('data/woodstock_model_files/tsa17.yld', 'w') as file:\n",
    "        tot=[]\n",
    "        tot_b=[]\n",
    "        swd=[]\n",
    "        hwd=[]\n",
    "        for AU, au_row in curve_points_table.iterrows():\n",
    "\n",
    "            yname = 's%04d' % int(au_row.canfi_species)\n",
    "            yname_b = 'b%04d' % int(au_row.canfi_species)\n",
    "            curve_id = au_row.curve_id\n",
    "            mask = ('?', '?', str(AU), '?', str(curve_id))\n",
    "            mask_biomass = ('?', '?', str(AU), '?', str(curve_id))\n",
    "            points = [(x*10, au_row['X%i' % (x*10)]) for x in range(36)]\n",
    "            c = ws3.core.Curve(yname, points=points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print('*Y', ' '.join(v for v in mask), file=file)\n",
    "            print(yname, '1', ' '.join(str(int(c[x])) for x in range(0, 350, 10)), file=file)\n",
    "            b_points = [(x*10, au_row['X%i' % (x*10)]+1) for x in range(36)]\n",
    "            # b_points = [(x*10, au_row['X%i' % (x*10)]) for x in range(36)]\n",
    "            biomass_points = [(x, au_row['a'] * (y ** au_row['a'])) for x, y in b_points]\n",
    "            biomass_c = ws3.core.Curve(yname_b, points=biomass_points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print(yname_b, '1', ' '.join(str(int(biomass_c[x])) for x in range(0, 350, 10)), file=file)\n",
    "            if yname_b not in tot_b:\n",
    "                tot_b.append(yname_b)\n",
    "            if yname not in tot:\n",
    "                tot.append(yname)\n",
    "            if int(au_row.canfi_species) > 1200:\n",
    "                if yname not in hwd: hwd.append(yname)\n",
    "            else:\n",
    "                if yname not in swd: swd.append(yname)\n",
    "        print('*YC ? ? ? ? ?', file=file)\n",
    "        print('totvol _SUM(%s)' % ', '.join(map(str, tot)), file=file)\n",
    "        print('totvol_b _SUM(%s)' % ', '.join(map(str, tot_b)), file=file)\n",
    "        print('swdvol _SUM(%s)' % ', '.join(map(str, swd)), file=file)\n",
    "        print('hwdvol _SUM(%s)' % ', '.join(map(str, hwd)), file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83482c9-eae5-456f-8a86-e64de8bc3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/woodstock_model_files/tsa17.yld', 'w') as file:\n",
    "        tot=[]\n",
    "        tot_st=[]\n",
    "        tot_bk=[]\n",
    "        tot_br=[]\n",
    "        tot_fl=[]\n",
    "        swd=[]\n",
    "        hwd=[]\n",
    "        for AU, au_row in curve_points_table.iterrows():\n",
    "            yname = 's%04d' % int(au_row.canfi_species)\n",
    "            yname_st = 'st%04d' % int(au_row.canfi_species)\n",
    "            yname_bk = 'bk%04d' % int(au_row.canfi_species)\n",
    "            yname_br = 'br%04d' % int(au_row.canfi_species)\n",
    "            yname_fl = 'fl%04d' % int(au_row.canfi_species)\n",
    "            curve_id = au_row.curve_id\n",
    "            mask = ('?', '?', str(AU), '?', str(curve_id))\n",
    "            points = [(x*10, au_row['X%i' % (x*10)]) for x in range(36)]\n",
    "            c = ws3.core.Curve(yname, points=points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print('*Y', ' '.join(v for v in mask), file=file)\n",
    "            print(yname, '1', ' '.join(str(int(c[x])) for x in range(0, 350, 10)), file=file)\n",
    "            stemwood_points = [(x, au_row['a'] * (y ** au_row['b'])) for x, y in points]\n",
    "            stemwood_curve = ws3.core.Curve(yname_st, points=stemwood_points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print(yname_st, '1', ' '.join(str(int(stemwood_curve[x])) for x in range(0, 350, 10)), file=file)\n",
    "            bark_points = [(x, math.exp(au_row['a1'] + au_row['a2'] * y + au_row['a3'] * math.log(y+5)) * au_row['a'] * (y ** au_row['b'])) for x, y in points]\n",
    "            bark_curve = ws3.core.Curve(yname_bk, points=bark_points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print(yname_bk, '1', ' '.join(str(round(bark_curve[x],3)) for x in range(0, 350, 10)), file=file)\n",
    "            branches_points = [(x, math.exp(au_row['b1'] + au_row['b2'] * y + au_row['b3'] * math.log(y+5)) * au_row['a'] * (y ** au_row['b'])) for x, y in points]\n",
    "            branches_curve = ws3.core.Curve(yname_br, points=branches_points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print(yname_br, '1', ' '.join(str(round(branches_curve[x],3)) for x in range(0, 350, 10)), file=file)\n",
    "            foliage_points = [(x, math.exp(au_row['c1'] + au_row['c2'] * y + au_row['c3'] * math.log(y+5)) * au_row['a'] * (y ** au_row['b'])) for x, y in points]\n",
    "            foliage_curve = ws3.core.Curve(yname_fl, points=foliage_points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print(yname_fl, '1', ' '.join(str(round(foliage_curve[x],3)) for x in range(0, 350, 10)), file=file)\n",
    "            if yname_st not in tot_st:\n",
    "                tot_st.append(yname_st)\n",
    "            if yname_bk not in tot_bk:\n",
    "                tot_bk.append(yname_bk)\n",
    "            if yname_br not in tot_br:\n",
    "                tot_br.append(yname_br)\n",
    "            if yname_fl not in tot_fl:\n",
    "                tot_fl.append(yname_fl)\n",
    "            if yname not in tot:\n",
    "                tot.append(yname)\n",
    "            if int(au_row.canfi_species) > 1200:\n",
    "                if yname not in hwd: hwd.append(yname)\n",
    "            else:\n",
    "                if yname not in swd: swd.append(yname)\n",
    "        print('*YC ? ? ? ? ?', file=file)\n",
    "        print('totvol _SUM(%s)' % ', '.join(map(str, tot)), file=file)\n",
    "        print('totvol_st _SUM(%s)' % ', '.join(map(str, tot_st)), file=file)\n",
    "        print('totvol_bk _SUM(%s)' % ', '.join(map(str, tot_bk)), file=file)\n",
    "        print('totvol_br _SUM(%s)' % ', '.join(map(str, tot_br)), file=file)\n",
    "        print('totvol_fl _SUM(%s)' % ', '.join(map(str, tot_fl)), file=file)\n",
    "        print('swdvol _SUM(%s)' % ', '.join(map(str, swd)), file=file)\n",
    "        print('hwdvol _SUM(%s)' % ', '.join(map(str, hwd)), file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd641b3-d2cb-4239-898c-5d65521276f7",
   "metadata": {},
   "source": [
    "## ACTIONS section\n",
    "\n",
    "The ACTIONS section defines actions that can be applied in the model (e.g., harvesting, planting, thinning, fertilization, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c46b4d-471f-4038-92dd-48a0751d8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/woodstock_model_files/tsa17.act', 'w') as file:\n",
    "    print('ACTIONS', file=file)\n",
    "    print('*ACTION harvest Y', file=file)\n",
    "    print('*OPERABLE harvest', file=file)\n",
    "    print('? 1 ? ? ? _AGE >= 90 AND _AGE <= 600', file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0ae8e-5882-4248-b140-52db2b7ffb76",
   "metadata": {},
   "source": [
    "## TRANSITIONS section\n",
    "\n",
    "The TRANSITIONS section defines transitions (i.e., transition to a new development type and age class induced by applying a specific action to a specific combination of development type and age class). If there were no transitions in a forest estate model, it would simply be aging (i.e., growing) the forest forward from time step 1 through to time step N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d3258-750c-4de4-a07e-bdf6d8206138",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/woodstock_model_files/tsa17.trn', 'w') as file:\n",
    "    acode = 'harvest'\n",
    "    print('*CASE', acode, file=file)\n",
    "    record_au = set()\n",
    "    for au_id, au_row in stands_table.iterrows():\n",
    "        if au_row.theme2 in record_au: continue\n",
    "        if not au_row.theme1: continue\n",
    "        target_curve_id = au_row.theme4  \n",
    "        smask = ' '.join(('?', '?' , str(target_curve_id), '?', '?'))\n",
    "        tmask = ' '.join(('?', '?' , '?', '?', str(target_curve_id)))\n",
    "        print('*SOURCE', smask, file=file)\n",
    "        print('*TARGET', tmask, '100', file=file)\n",
    "        record_au.add(au_row.theme2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01c279-bd55-4588-9286-1763d8046dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c899680-6678-49fe-9e7c-c7e0028f38f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36197e-034a-49eb-82ee-d471f31d5472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv:foo)",
   "language": "python",
   "name": "foo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
